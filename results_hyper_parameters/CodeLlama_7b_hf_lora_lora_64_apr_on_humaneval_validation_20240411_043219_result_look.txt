
'======/c21071/lgc/llmpeft4apr/results_hyper_parameters/CodeLlama_7b_hf_lora_lora_64_apr_on_humaneval_validation_20240411_043219.json results:===='
Model: CodeLlama-7b-hf
PEFT Method: lora  
train_dataset: lora_64_apr  
validation benchmark : humaneval 
validation result: 
pass@0:plausible pathces - 0, total  problems - 163, correctness pecent - 0.0
pass@1:plausible pathces - 55, total  problems - 163, correctness pecent - 0.3374233128834356
pass@2:plausible pathces - 66, total  problems - 163, correctness pecent - 0.4049079754601227
pass@3:plausible pathces - 75, total  problems - 163, correctness pecent - 0.4601226993865031
pass@4:plausible pathces - 80, total  problems - 163, correctness pecent - 0.49079754601226994
pass@5:plausible pathces - 85, total  problems - 163, correctness pecent - 0.5214723926380368
pass@6:plausible pathces - 88, total  problems - 163, correctness pecent - 0.5398773006134969
pass@7:plausible pathces - 92, total  problems - 163, correctness pecent - 0.5644171779141104
pass@8:plausible pathces - 94, total  problems - 163, correctness pecent - 0.5766871165644172
pass@9:plausible pathces - 95, total  problems - 163, correctness pecent - 0.5828220858895705
pass@10:plausible pathces - 96, total  problems - 163, correctness pecent - 0.588957055214724
