
'======/c21071/lgc/llmpeft4apr/results_hyper_parameters/CodeLlama_7b_hf_IA3_apr_5k_on_humaneval_validation_20240411_043037.json results:===='
Model: CodeLlama-7b-hf
PEFT Method: IA3  
train_dataset: apr_5k  
validation benchmark : humaneval 
validation result: 
pass@0:plausible pathces - 0, total  problems - 163, correctness pecent - 0.0
pass@1:plausible pathces - 38, total  problems - 163, correctness pecent - 0.2331288343558282
pass@2:plausible pathces - 56, total  problems - 163, correctness pecent - 0.34355828220858897
pass@3:plausible pathces - 70, total  problems - 163, correctness pecent - 0.4294478527607362
pass@4:plausible pathces - 77, total  problems - 163, correctness pecent - 0.4723926380368098
pass@5:plausible pathces - 83, total  problems - 163, correctness pecent - 0.50920245398773
pass@6:plausible pathces - 86, total  problems - 163, correctness pecent - 0.5276073619631901
pass@7:plausible pathces - 89, total  problems - 163, correctness pecent - 0.5460122699386503
pass@8:plausible pathces - 92, total  problems - 163, correctness pecent - 0.5644171779141104
pass@9:plausible pathces - 93, total  problems - 163, correctness pecent - 0.5705521472392638
pass@10:plausible pathces - 96, total  problems - 163, correctness pecent - 0.588957055214724
