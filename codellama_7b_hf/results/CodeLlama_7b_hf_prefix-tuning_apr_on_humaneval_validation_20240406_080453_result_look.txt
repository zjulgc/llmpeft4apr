
'====== llmpeft4apr/results/CodeLlama_7b_hf_prefix-tuning_apr_on_humaneval_validation_20240406_080453.json results:===='
Model: CodeLlama-7b-hf
PEFT Method: prefix-tuning  
train_dataset: apr  
validation benchmark : humaneval 
validation result: 
pass@0:plausible pathces - 0, total  problems - 163, correctness pecent - 0.0
pass@1:plausible pathces - 39, total  problems - 163, correctness pecent - 0.2392638036809816
pass@2:plausible pathces - 53, total  problems - 163, correctness pecent - 0.32515337423312884
pass@3:plausible pathces - 61, total  problems - 163, correctness pecent - 0.37423312883435583
pass@4:plausible pathces - 66, total  problems - 163, correctness pecent - 0.4049079754601227
pass@5:plausible pathces - 71, total  problems - 163, correctness pecent - 0.43558282208588955
pass@6:plausible pathces - 75, total  problems - 163, correctness pecent - 0.4601226993865031
pass@7:plausible pathces - 80, total  problems - 163, correctness pecent - 0.49079754601226994
pass@8:plausible pathces - 81, total  problems - 163, correctness pecent - 0.49693251533742333
pass@9:plausible pathces - 81, total  problems - 163, correctness pecent - 0.49693251533742333
pass@10:plausible pathces - 81, total  problems - 163, correctness pecent - 0.49693251533742333
