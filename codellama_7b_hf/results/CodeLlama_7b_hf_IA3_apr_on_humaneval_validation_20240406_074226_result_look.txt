
'====== llmpeft4apr/results/CodeLlama_7b_hf_IA3_apr_on_humaneval_validation_20240406_074226.json results:===='
Model: CodeLlama-7b-hf
PEFT Method: IA3  
train_dataset: apr  
validation benchmark : humaneval 
validation result: 
pass@0:plausible pathces - 0, total  problems - 163, correctness pecent - 0.0
pass@1:plausible pathces - 37, total  problems - 163, correctness pecent - 0.22699386503067484
pass@2:plausible pathces - 61, total  problems - 163, correctness pecent - 0.37423312883435583
pass@3:plausible pathces - 70, total  problems - 163, correctness pecent - 0.4294478527607362
pass@4:plausible pathces - 81, total  problems - 163, correctness pecent - 0.49693251533742333
pass@5:plausible pathces - 87, total  problems - 163, correctness pecent - 0.5337423312883436
pass@6:plausible pathces - 90, total  problems - 163, correctness pecent - 0.5521472392638037
pass@7:plausible pathces - 92, total  problems - 163, correctness pecent - 0.5644171779141104
pass@8:plausible pathces - 95, total  problems - 163, correctness pecent - 0.5828220858895705
pass@9:plausible pathces - 96, total  problems - 163, correctness pecent - 0.588957055214724
pass@10:plausible pathces - 99, total  problems - 163, correctness pecent - 0.6073619631901841
