
'====== llmpeft4apr/results/Llama_2_7b_hf_prefix-tuning_apr_on_defects4j_validation_20240407_042813.json results:===='
Model: Llama-2-7b-hf
PEFT Method: prefix-tuning  
train_dataset: apr  
validation benchmark : defects4j 
validation result: 
pass@0:plausible pathces - 0, total  problems - 217, correctness pecent - 0.0
pass@1:plausible pathces - 2, total  problems - 217, correctness pecent - 0.009216589861751152
pass@2:plausible pathces - 2, total  problems - 217, correctness pecent - 0.009216589861751152
pass@3:plausible pathces - 2, total  problems - 217, correctness pecent - 0.009216589861751152
pass@4:plausible pathces - 2, total  problems - 217, correctness pecent - 0.009216589861751152
pass@5:plausible pathces - 2, total  problems - 217, correctness pecent - 0.009216589861751152
pass@6:plausible pathces - 2, total  problems - 217, correctness pecent - 0.009216589861751152
pass@7:plausible pathces - 2, total  problems - 217, correctness pecent - 0.009216589861751152
pass@8:plausible pathces - 2, total  problems - 217, correctness pecent - 0.009216589861751152
pass@9:plausible pathces - 3, total  problems - 217, correctness pecent - 0.013824884792626729
pass@10:plausible pathces - 3, total  problems - 217, correctness pecent - 0.013824884792626729
